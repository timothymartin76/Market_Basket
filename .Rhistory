plot(cpi, xaxt="n", ylab="CPI", xlab="")
axis(1, labels=paste(year,quarter,sep="Q"), at=1:12, las=3)
cor(year,cpi)
cor(quarter,cpi)
fit <- lm(cpi ~ year + quarter)
fit
cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 +fit$coefficients[[3]]*(1:4)
attributes(fit)
fit$coefficients
residuals(fit)
summary(fit)
plot(fit)
axis(1, at=1:16, las=3,labels=c(paste(year,quarter,sep="Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
# Generalized linear regression
data("bodyfat", package = "mboost")
str(bodyfat)
myFormula <- DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth
bodyfat.glm <- glm(myFormula, family = gaussian("log"), data = bodyfat)
summary(bodyfat.glm)
pred <- predict(bodyfat.glm, type = "response")
plot(bodyfat$DEXfat, pred, xlab="Observed Values", ylab="Predicted Values")
# VCD: A package for analyzing categorical data
library(vcd)
rseed <- 1071
data("Arthritis", package = "vcd")
(art <- xtabs(~ Treatment + Improved, data = Arthritis, subset = Sex == "Female"))
mosaic(art)
assoc(art)
data("alzheimer", package = "coin")
alz <- xtabs(~ smoking + disease + gender, data = alzheimer)
alz
data("SexualFun")
agreementplot(t(SexualFun))
data("HairEyeColor")
str(HairEyeColor)
(x <- margin.table(HairEyeColor, c(1, 2)))
assoc(x)
assoc(x, main = "Relation between hair and eye color", shade = TRUE)
(x <- margin.table(HairEyeColor, c(1, 3)))
chisq.test(x)
assoc(x, main = "Relation between hair color and sex", shade = TRUE)
assocstats(x)
Library ggmap
=======================
```{r}
library(ggmap)
```
```{r}
data(package="ggmap")
```
```{r}
str(crime)
```
```{r}
map <- get_cloudmademap(api_key = '')
ggmap(map)
```
```{r}
distQueryCheck()
geocodeQueryCheck()
```
```{r}
gc <- geocode('waco,texas')
center <- as.numeric(gc)
ggmap(get_map(location=center,color='bw',scale=2))
```
```{r}
gc <- geocode('duncan hall, rice university')
google <- get_googlemap('rice university', zoom = 15)
ggmap(google) + geom_point(aes(x = lon, y = lat), data = gc, colour = 'red', size = 2)
```
```{r}
bbox <- as.numeric(attr(google, 'bb'))[c(2,1,4,3)]
names(bbox) <- c('left','bottom','right','top')
stamen <- get_stamenmap(bbox, zoom = 15)
ggmap(stamen) + geom_point(aes(x = lon, y = lat), data = gc, colour = 'red', size = 2)
```
```{r}
osm <- get_openstreetmap(bbox, scale = OSM_scale_lookup(15))
ggmap(osm) + geom_point(aes(x = lon, y = lat), data = gc, colour = 'red', size = 2)
```
```{r}
ggmap(get_stamenmap(bbox, zoom = 15, maptype = 'watercolor'))+ geom_point(aes(x = lon, y = lat), data = gc, colour = 'red', size = 2)
```
```{r}
ggmap(get_stamenmap(bbox, zoom = 15, maptype = 'toner'))+ geom_point(aes(x = lon, y = lat), data = gc, colour = 'red', size = 2)
```
```{r}
municatlonlat2 <- read.csv("~/Desktop/Docs/CAT/municatlonlat2.csv")
lonlat <- municatlonlat2
```
```{r}
barcelona <- geocode('Barcelona,Spain')
barcelona
```
```{r}
center <- as.numeric(barcelona)
ggmap(get_map(location=center,scale=2,color='bw',zoom=8))
ggmap(get_map(location=center,scale=2,color='bw',zoom=8))+ geom_point(aes(x=longitude,y=latitude),data=lonlat)
```
```{r}
eleccions2012 <- read.csv("~/Desktop/Docs/CAT/elecat2012.csv")
ele1 <- eleccions2012
str(ele1)
str(lonlat)
```
```{r}
ele2 <- cbind(ele1,lonlat$longitude,lonlat$latitude)
str(ele2)
```
```{r}
ggmap(get_map(location=center,scale=2,color='bw',zoom=8))+ geom_point(aes(x=lonlat$longitude,y=lonlat$latitude,size=total.votos),data=ele2)
```
# maping connections
library(maps)
library(geosphere)
map("state")
map("world")
# Limiting boundaries
xlim <- c(-171.738281, -56.601563)
ylim <- c(12.039321, 71.856229)
map("world", col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05, xlim=xlim, ylim=ylim)
# Drawing connecting lines
lat_ca <- 39.164141
lon_ca <- -121.640625
lat_me <- 45.213004
lon_me <- -68.906250
inter <- gcIntermediate(c(lon_ca, lat_ca), c(lon_me, lat_me), n=50, addStartEnd=TRUE)
lines(inter)
lat_tx <- 29.954935
lon_tx <- -98.701172
inter2 <- gcIntermediate(c(lon_ca, lat_ca), c(lon_tx, lat_tx), n=50, addStartEnd=TRUE)
lines(inter2, col="red")
# Load flight data
airports <- read.csv("http://datasets.flowingdata.com/tuts/maparcs/airports.csv", header=TRUE)
flights <- read.csv("http://datasets.flowingdata.com/tuts/maparcs/flights.csv", header=TRUE, as.is=TRUE)
# Draw multiple connections
map("world", col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05, xlim=xlim, ylim=ylim)
fsub <- flights[flights$airport1 == "ORD" & flights$cnt>=20,]
for (j in 1:length(fsub$airline)) {
air1 <- airports[airports$iata == fsub[j,]$airport1,]
air2 <- airports[airports$iata == fsub[j,]$airport2,]
inter <- gcIntermediate(c(air1[1,]$long, air1[1,]$lat), c(air2[1,]$long, air2[1,]$lat), n=100, addStartEnd=TRUE)
lines(inter, col="black", lwd=0.2)
}
# Color for clarity
pal <- colorRampPalette(c("#f2f2f2", "black"))
colors <- pal(100)
map("world", col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05, xlim=xlim, ylim=ylim)
fsub <- flights[flights$airline == "AA",]
maxcnt <- max(fsub$cnt)
for (j in 1:length(fsub$airline)) {
air1 <- airports[airports$iata == fsub[j,]$airport1,]
air2 <- airports[airports$iata == fsub[j,]$airport2,]
inter <- gcIntermediate(c(air1[1,]$long, air1[1,]$lat), c(air2[1,]$long, air2[1,]$lat), n=100, addStartEnd=TRUE)
colindex <- round( (fsub[j,]$cnt / maxcnt) * length(colors) )
lines(inter, col=colors[colindex], lwd=0.8)
}
# refining color
pal <- colorRampPalette(c("#f2f2f2", "black"))
pal <- colorRampPalette(c("#f2f2f2", "red"))
colors <- pal(100)
map("world", col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05, xlim=xlim, ylim=ylim)
fsub <- flights[flights$airline == "AA",]
fsub <- fsub[order(fsub$cnt),]
maxcnt <- max(fsub$cnt)
for (j in 1:length(fsub$airline)) {
air1 <- airports[airports$iata == fsub[j,]$airport1,]
air2 <- airports[airports$iata == fsub[j,]$airport2,]
inter <- gcIntermediate(c(air1[1,]$long, air1[1,]$lat), c(air2[1,]$long, air2[1,]$lat), n=100, addStartEnd=TRUE)
colindex <- round( (fsub[j,]$cnt / maxcnt) * length(colors) )
lines(inter, col=colors[colindex], lwd=0.8)
}
# clustering
# k-Means clustering
data(iris)
iris2 <- iris
str(iris2)
# remove species from the data to cluster
iris2$Species <- NULL
str(iris2)
# Apply kmeans() to iris2, and store the clustering result in kc. The cluster number is set to 3.
(kmeans.result <- kmeans(iris2, 3))
# Compare the Species label with the clustering result
table(iris$Species, kmeans.result$cluster)
plot(iris2[c("Sepal.Length", "Sepal.Width")], col = kmeans.result$cluster)
# k-Medoids clustering
# The k-medoids clustering is very similar to k-means, and the major difference between them is that: while a cluster is represented with its center
# in the k-means algorithm, it is represented with the object closest to the center of the cluster in the k-medoids clustering
library(fpc)
pamk.result <- pamk(iris2)
# number of clusters
pamk.result$nc
# check clustering against real species
table(pamk.result$pamobject$clustering, iris$Species)
layout(matrix(c(1,2),1,2)) # 2 graphs per page
plot(pamk.result$pamobject)
pam.result <- pam(iris2, 3)
table(pam.result$clustering, iris$Species)
layout(matrix(c(1,2),1,2)) # 2 graphs per page
plot(pam.result)
layout(matrix(1)) # change back to one graph per page
# Hierarchical clustering
# Draw a sample of 40 records from iris data, and remove variable Species
idx <- sample(1:dim(iris)[1], 40)
irisSample <- iris[idx,]
irisSample$Species <- NULL
str(irisSample)
# Hierarchical clustering
hc <- hclust(dist(irisSample), method="ave")
plot(hc, hang = -1, labels=iris$Species[idx])
# Density-based clustering
# The idea of density-based clustering is to group objects into one cluster
# if they are connected to one another by densely populated area.
library(fpc)
iris2 <- iris[-5] # remove class tags
ds <- dbscan(iris2, eps=0.42, MinPts=5)
# compare clusters with original class labels
table(ds$cluster, iris$Species)
plot(ds, iris2)
plot(ds, iris2[c(1,4)])
plotcluster(iris2, ds$cluster)
# create a new dataset for labeling
set.seed(435)
idx <- sample(1:nrow(iris), 10)
newData <- iris[idx,-5]
newData <- newData + matrix(runif(10*4, min=0, max=0.2), nrow=10, ncol=4)
# label new data
myPred <- predict(ds, iris2, newData)
# check the labels assigned to new data
plot(iris2[c(1,4)], col=1+ds$cluster)
points(newData[c(1,4)], pch="*", col=1+myPred, cex=3)
# check cluster labels
table(myPred, iris$Species[idx])
doInstall <- TRUE  # Change to FALSE if you don't want packages installed.
toInstall <- c("sna", "igraph", "ggplot2", "Hmisc", "reshape2")
if(doInstall){install.packages(toInstall, repos = "http://cran.r-project.org")}
lapply(toInstall, library, character.only = TRUE)
# Empty ggplot2 theme
new_theme_empty <- theme_bw()
new_theme_empty$line <- element_blank()
new_theme_empty$rect <- element_blank()
new_theme_empty$strip.text <- element_blank()
new_theme_empty$axis.text <- element_blank()
new_theme_empty$plot.title <- element_blank()
new_theme_empty$axis.title <- element_blank()
new_theme_empty$plot.margin <- structure(c(0, 0, -1, -1), unit = "lines",
valid.unit = 3L, class = "unit")
data(coleman)  # Load a high school friendship network
adjacencyMatrix <- coleman[1, , ]  # Fall semester
layoutCoordinates <- gplot(adjacencyMatrix)  # Get graph layout coordinates
adjacencyList <- melt(adjacencyMatrix)  # Convert to list of ties only
adjacencyList <- adjacencyList[adjacencyList$value > 0, ]
# Function to generate paths between each connected node
edgeMaker <- function(whichRow, len = 100, curved = TRUE){
fromC <- layoutCoordinates[adjacencyList[whichRow, 1], ]  # Origin
toC <- layoutCoordinates[adjacencyList[whichRow, 2], ]  # Terminus
# Add curve:
graphCenter <- colMeans(layoutCoordinates)  # Center of the overall graph
bezierMid <- c(fromC[1], toC[2])  # A midpoint, for bended edges
distance1 <- sum((graphCenter - bezierMid)^2)
if(distance1 < sum((graphCenter - c(toC[1], fromC[2]))^2)){
bezierMid <- c(toC[1], fromC[2])
}  # To select the best Bezier midpoint
bezierMid <- (fromC + toC + bezierMid) / 3  # Moderate the Bezier midpoint
if(curved == FALSE){bezierMid <- (fromC + toC) / 2}  # Remove the curve
edge <- data.frame(bezier(c(fromC[1], bezierMid[1], toC[1]),  # Generate
c(fromC[2], bezierMid[2], toC[2]),  # X & y
evaluation = len))  # Bezier path coordinates
edge$Sequence <- 1:len  # For size and colour weighting in plot
edge$Group <- paste(adjacencyList[whichRow, 1:2], collapse = ">")
return(edge)
}
# Generate a (curved) edge path for each pair of connected nodes
allEdges <- lapply(1:nrow(adjacencyList), edgeMaker, len = 500, curved = TRUE)
allEdges <- do.call(rbind, allEdges)  # a fine-grained path ^, with bend ^
zp1 <- ggplot(allEdges)  # Pretty simple plot code
zp1 <- zp1 + geom_path(aes(x = x, y = y, group = Group,  # Edges with gradient
colour = Sequence, size = -Sequence))  # and taper
zp1 <- zp1 + geom_point(data = data.frame(layoutCoordinates),  # Add nodes
aes(x = x, y = y), size = 2, pch = 21,
colour = "black", fill = "gray")  # Customize gradient v
zp1 <- zp1 + scale_colour_gradient(low = gray(0), high = gray(9/10), guide = "none")
zp1 <- zp1 + scale_size(range = c(1/10, 1), guide = "none")  # Customize taper
zp1 <- zp1 + new_theme_empty  # Clean up plot
print(zp1)
# Looks better when saved as a PNG:
ggsave("ggplot directed network.png", zp1, h = 9/2, w = 9/2, type = "cairo-png")
install.packages(toInstall, repos = "http://cran.r-project.org")
# ejemplos con igraph
g1 <- aging.prefatt.game(10000, pa.exp=1, aging.exp=0, aging.bin=1000)
max(degree(g1))
g.1 <- graph( c(1,3,2,3,3,4,4,5) )
alpha.centrality(g.1)
articulation.points(g.1)
as.directed(g.1, mode = c("mutual", "arbitrary"))
as.undirected(g.1, mode = c("collapse", "each", "mutual"),edge.attr.comb = getIgraphOpt("edge.attr.comb"))
assortativity(g.1,3)
assortativity.degree(erdos.renyi.game(10000,3/10000))
g <- graph.ring(10)
g <- set.graph.attribute(g, "name", "RING")
g <- set.vertex.attribute(g, "color", value=c("red", "green"))
get.vertex.attribute(g, "color")
g <- set.edge.attribute(g, "weight", value=runif(ecount(g)))
get.edge.attribute(g, "weight")
betweenness(g)
edge.betweenness(g)
biconnected.components(g)
bipartite.mapping(g)
g <- graph.full.bipartite(10,5)
proj <- bipartite.projection(g)
graph.isomorphic(proj[[1]], graph.full(10))
g <- graph.ring(10)
closeness(g)
clusters(g)
is.connected(g)
no.clusters(g)
cluster.distribution(g)
cocitation(g)
bibcoupling(g)
cohesive.blocks(g, labels = TRUE)
mwBlocks <- cohesive.blocks(g)
mwBlocks
mwBlocks
blocks(mwBlocks)
cohesion(mwBlocks)
karate <- graph.famous("Zachary")
wc <- walktrap.community(karate)
modularity(wc)
membership(wc)
plot(wc, karate)
library("devtools", lib.loc="C:/Program Files/R/R-3.1.3/library")
devtools::install_github("timelyportfolio/rcdimple") # only for htmlwidget functionality
devtools::install_github("hrbrmstr/waffle")
install.packages("waffle")
require(waffle)
library("ggplot2", lib.loc="C:/Program Files/R/R-3.1.3/library")
library("waffle", lib.loc="C:/Program Files/R/R-3.1.3/library")
install.packages("reshape2")
require(reshape2)
library("waffle", lib.loc="C:/Program Files/R/R-3.1.3/library")
require(gtable)
require(grid)
packageVersion("waffle")
parts <- c(80, 30, 20, 10)
waffle(parts, rows=8)
parts <- c(`Un-breached\nUS Population`=(318-11-79), `Premera`=11, `Anthem`=79)
waffle(parts, rows=8, size=1, colors=c("#969696", "#1879bf", "#009bda"))
waffle(parts/10, rows=3, colors=c("#969696", "#1879bf", "#009bda"))
savings <- c(`Mortgage ($84,911)`=84911, `Auto and\ntuition loans ($14,414)`=14414,
`Home equity loans ($10,062)`=10062, `Credit Cards ($8,565)`=8565)
waffle(savings/392, rows=7, size=0.5,
colors=c("#c7d4b6", "#a3aabd", "#a0d0de", "#97b5cf"))
# https://eagereyes.org/techniques/square-pie-charts
professional <- c(`Male`=44, `Female (56%)`=56)
waffle(professional, rows=10, size=0.5, colors=c("#af9139", "#544616"))
pain.adult.1997 <- c( `YOY (406)`=406, `Adult (24)`=24)
A <- waffle(pain.adult.1997/2, rows=7, size=0.5,
colors=c("#c7d4b6", "#a3aabd"),
title="Paine Run Brook Trout Abundance (1997)",
xlab="1 square = 2 fish", pad=3)
pine.adult.1997 <- c( `YOY (221)`=221, `Adult (143)`=143)
B <- waffle(pine.adult.1997/2, rows=7, size=0.5,
colors=c("#c7d4b6", "#a3aabd"),
title="Piney River Brook Trout Abundance (1997)",
xlab="1 square = 2 fish", pad=8)
stan.adult.1997 <- c( `YOY (270)`=270, `Adult (197)`=197)
C <- waffle(stan.adult.1997/2, rows=7, size=0.5,
colors=c("#c7d4b6", "#a3aabd"),
title="Staunton River Trout Abundance (1997)",
xlab="1 square = 2 fish")
iron(A, B, C)
nyc<- c('Transfer 75.7%'=75.7, 'Containment 10.6%'=10.6, 'Fed/State 6.6%'=6.6, 'City Agency 6.3%'=6.3)
AA <- waffle(nyc, rows=7, size=0.5,
colors=c("#c7d4b6", "#a3aabd"),
title="NLU Performance and Transfer")
iron(AA)
AA <- waffle(nyc, rows=7, size=0.5,title="NLU Performance and Transfer")
iron(AA)
AA <- waffle(nyc, rows=7, size=0.5, colors=c("#1A1F2B", "#30395C", "#4A6491", "#85A5CC"), title="NLU Performance and Transfer")
iron(AA)
AA <- waffle(nyc, rows=7, size=0.5, colors=c("#225378", "#EB7F00", "#F3FFE2", "#1695A3"), title="NLU Performance and Transfer")
iron(AA)
nyc2<- c('Transfer 77.9%'=77.9, 'Containment 9%'=10.6, 'Fed/State 6.6%'=6.6, 'City Agency 6.3%'=6.3)
nyc3<- c('Transfer 77.9%'=77.9, 'Containment 9.7%'=9.7, 'Fed/State Agency 5.9%'=5.9, 'City Agency 5.8%'=5.8, 'Other 0.8%'=0.8)
BB <- waffle(nyc2, rows=7, size=0.5,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer")
iron(BB)
BB <- waffle(nyc2, rows=7, size=0.5,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer", )+
theme_wsj() +
scale_x_continuous(breaks=NULL) +
scale_y_continuous(breaks=NULL)
BB <- waffle(nyc2, rows=7, size=0.5,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer", )
iron(BB)
BB <- waffle(nyc2, rows=10, size=2,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer")
iron(BB)
BB <- waffle(nyc2, rows=10, size=5,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer")
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.5,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer")
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer")
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.title = element_text(colour="blue", face="bold", size=14))
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(colour="blue", face="bold", size=16))
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(colour="blue", face="bold", size=16))
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(BB)
BB <- waffle(nyc2, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
library(gcookbook)
tophit<- tophitters2001[1:25, ]
View(tophit)
ggplot(tophit, aes(x=avg,y=name)) + geom_point()
tophit[, c("name", "lg", "avg")]
ggplot(tophit, aes(x=avg, y=reorder(name, avg))) + geom_point(size=5) + theme_bw() + theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank() panel.grid.major.y = element_line(colour="grey60", linetype="dashed"))
ggplot( tophit, aes( x = avg, y = reorder( name, avg))) + geom_point( size = 5) + # Use a larger dot theme_bw() + theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line( colour ="grey60", linetype ="dashed"))
ggplot( tophit, aes( x = avg, y = reorder( name, avg))) + geom_point( size = 5) + # Use a larger dot theme_bw() + theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line( colour ="grey60", linetype ="dashed"))
library( gcookbook) # For the data set tophit <- tophitters2001[ 1: 25, ] # Take the top 25 from the tophitters data set ggplot( tophit, aes( x = avg, y = name)) + geom_point()
library(gcookbook) # For the data set tophit
tophit <- tophitters2001[ 1: 25, ]
ggplot( tophit, aes( x = avg, y = name)) + geom_point()
library("ggplot2", lib.loc="C:/Program Files/R/R-3.1.3/library")
ggplot( tophit, aes( x = avg, y = name)) + geom_point()
tophit[, c("name", "lg", "avg")]
ggplot(tophit, aes( x = avg, y = reorder( name, avg))) + geom_point( size = 5) + # Use a larger dot theme_bw() + theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line( colour ="grey60", linetype ="dashed"))
ggplot(tophit, aes(x = avg, y = reorder(name, avg))) + geom_point(size = 5) + theme_bw() + theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line( colour ="grey60", linetype ="dashed"))
ggplot(tophit, aes(x = avg, y = name)) + geom_segment( aes( yend = name), xend = 0, colour ="grey50") + geom_point( size = 5, aes(colour = lg)) + scale_colour_brewer(palette ="Set1", limits = c("NL","AL")) + theme_bw() + theme(panel.grid.major.y = element_blank()
getwd()
library(waffle)
require(ggplot2)
require(gtable)
require(grid)
nyc<- c('Transfer 77.6%'=77.6, 'Containment 9.6%'=9.6, 'Fed/State Agency 5.9%'=5.9, 'Other City Agency 2.4%'=2.4, 'Other 1.0%'=1, 'NYCHA 0.65'=0.6)
A <- waffle(nyc, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
nyc<- c('Transfer 77.6%'=77.6, 'Containment 9.6%'=9.6, 'Fed/State Agency 5.9%'=5.9, 'Other City Agency 6.2%'=6.2, 'Other 1.0%'=1)
A <- waffle(nyc, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
nyc<- c('Transfer 77.6%'=77, 'Containment 9.6%'=10, 'Fed/State Agency 5.9%'=6, 'Other City Agency 6.2%'=6, 'Other 1.0%'=1)
A <- waffle(nyc, rows=10, size=0.8,
colors=c("#004358", "#1F8A70", "#BEDB39", "#FFE11A", "#FD7400" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
A <- waffle(nyc, rows=10, size=0.8,
colors=c("#3182bd", "#6baed6", "#9ecae1", "#e6550d", "#fd8d3c" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
A <- waffle(nyc, rows=10, size=0.8,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
A <- waffle(nyc, rows=5, size=0.8,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
A <- waffle(nyc, rows=8, size=0.8,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(face="bold", size=14))
iron(A)
A <- waffle(nyc, rows=5, size=0.8,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(size=12))
iron(A)
A <- waffle(nyc, rows=5, size=1,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(size=12))
iron(A)
A <- waffle(nyc, rows=5, size=0.5,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(size=12))
iron(A)
A <- waffle(nyc, rows=5, size=0.8,
colors=c("#6baed6", "#fd8d3c", "#9ecae1", "#9e9ac8", "#969696" ), title="NLU Performance & Transfer") + theme(legend.text = element_text(size=12))
iron(A)
library(devtools)
install_github("leeper/slopegraph")
library(httr)
set_config(
use_proxy(url="bcpxy.nycnet", port=8080, username="timothymartin76",password="chichewa1")
)
install_github("leeper/slopegraph")
require(slopegraph)
getwd()
require(arules)
install.packages("C:/Users/timartin/Downloads/arules_1.3-1.zip", repos = NULL)
library("arules", lib.loc="C:/Program Files/R/R-3.1.3/library")
getwd()
setwd("C:/MarketBasket")
require(arules)
require(arulesViz)
mydata<- read.transactions("MB1GOOD.csv" , format = "basket" ,  rm.duplicates = TRUE, sep= "," )
itemFrequencyPlot(mydata,topN=20,type="absolute", col="steelblue")
rules <- apriori(mydata, parameter = list(supp = 0.001, conf = 0.4, minlen=2))
rules<-sort(rules, by="lift", decreasing=TRUE)
options(digits=2)
inspect(rules[1:20])
## Remove redundancies
subset.matrix <- is.subset(rules, rules)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >= 1
rules.pruned <- rules[!redundant]
rules<-rules.pruned
write(rules, file = "data.csv",  sep = ",")
plot(rules, method="graph", main="", control=list(layout=igraph::with_graphopt()))
plot(rules, method="paracoord")
plot(rules, method="grouped")
